<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Cherry picking with Reinforcement learning">
  <meta name="keywords" content="Dyanmics Fine Manipulation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Cherrybot</title>
  <link rel="icon" href="static/images/favicon.svg">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">

      <div class="navbar-item has-dropdown is-hoverable">

      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Cherry picking with Reinforcement learning</h1>
          <!--
          <h3 class="title is-4 conference-authors"><a target="_blank" href="https://www.robot-learning.org/">CoRL 2021</a></h3>
          
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a target="_blank" href="https://mohitshridhar.com/">Mohit Shridhar</a><sup>1</sup>,</span>
            <span class="author-block">
              <a target="_blank" href="http://lucasmanuelli.com/">Lucas Manuelli</a><sup>2</sup>,</span>
            <span class="author-block">
              <a target="_blank" href="https://homes.cs.washington.edu/~fox/">Dieter Fox</a><sup>1, 2</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Washington,</span>
            <span class="author-block"><sup>2</sup>NVIDIA</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
                <span class="link-block">
                <a target="_blank" href="https://arxiv.org/pdf/2109.12098.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
               <span class="link-block">
                <a target="_blank" href="https://drive.google.com/file/d/1xzG5e1XF958HPuD_FZTiKROd9AQyd1fS/view?usp=sharing"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a target="_blank" href="https://youtu.be/UdzoagBgWTA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> 
               <span class="link-block">
                <a target="_blank" href="https://github.com/cliport/cliport"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>
            -->
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero teaser">
  <div class="container">
    <div class="wrappable_list">
      <span>
        <video autoplay loop muted>
          <source src="media/vids/tree_sitback.mp4" type="video/mp4"/>
          Video of robot picking a cherry from a tree.
        </video>
      </span>
      <span>
        <video autoplay loop muted>
          <source src="media/vids/sand.mp4" type="video/mp4"/>
          Video of a robot picking a cherry off of shifting sand.
        </video>
      </span>
      <span>
        <video autoplay loop muted>
          <source src="media/vids/human_drag_ball.mp4" type="video/mp4"/>
          Video of a robot grabbing a ball that is being shaken around by a hand.
        </video>
      </span>
      <span>
        <video autoplay loop muted>
          <source src="media/vids/grapes.mp4" type="video/mp4"/>
          Video of a robot picking up a grape from a pile of other grapes.
        </video>
      </span>
      <span>
        <video autoplay loop muted>
          <source src="media/vids/duck.mp4" type="video/mp4"/>
          Video of a robot picking up a rubber duck.
        </video>
      </span>
    </div>
  </div>

  <!-- <div class="container is-fullhd">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop height="100%">
        <source src="https://cliport.github.io/media/videos/10sim_web_teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
      </br>
        <span class="dcliport">Cherrybot</span> is an model-free reinforcement-learning agent that could generalize to varying perception noise; objects with different shape, size, texture; dynamic disturbance; objects with varying fluid support in zero-shot, <b>without further learning</b>.
      </h2>
    </div>
  </div> -->
</section>


<!-- 
<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop height="100%">
            <source src="https://cliport.github.io/media/videos/1_folding.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop height="100%">
            <source src="https://cliport.github.io/media/videos/4_chess.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop height="100%">
            <source src="https://cliport.github.io/media/videos/3_packing.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> 
-->






<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">The Problem</h2>
        <div class="content has-text-justified">
          <p>
            Grasping small objects surrounded by unstable or
            non-rigid material plays a crucial role in applications such as
            surgery, harvesting, construction, disaster recovery, and assisted
            feeding. This task is especially difficult when fine manipulation is
            required in the presence of sensor noise and perception errors;
            this inevitably triggers dynamic motion, which is challenging to
            model precisely.
          </p>
          <div>
            <p>
            Similar challenges arise in everyday interactions: to remove shells 
            from flowing egg whites, to grasp noodles from soup, and for surgeons to remove clots from deformable organs. 
            Given the ubiquitous nature of these problems, developing robotic 
            solutions to automate these has immense practical and economic value.
            </p>
            <div class="horizontal_list">
              <span class="list_image">
                <img src="media/imgs/egg-shells.jpg" class="interpolation-image" alt="Image of egg shells in egg yolk" style="max-width: 100%; max-height: 100%;" />
                <p class="image_caption">Picking up egg yolks</p>
              </span>
              <span class="list_image">
                <img src="media/imgs/noodles.jpg" class="interpolation-image" alt="Image of noodles being picked up with chopsticks" />
                <p class="image_caption">Picking up noodles</p>
              </span>
              <span class="list_image">
                <img src="media/imgs/surgery.jpg" class="interpolation-image" alt="Image of micro-surgery" />
                <p class="image_caption">Removing clots from deformable organs</p>
              </span>
            </div>
          </div>
          <p>
            This work presents CherryBot, an RL system for fine manipulation 
            that surpasses human reactivity for some dynamic
            grasping tasks. By carefully designing the training paradigm and
            algorithm, we study how to make a real-world robot learning
            system sample efficient and general while reducing the human
            effort required for supervision. Our system shows continual
            improvement through only <b>30 minutes</b> of real-world interaction:
            through reactive retries, it achieves an almost 100% success rate
            on the demanding task of using chopsticks to grasp small objects
            swinging in the air. We demonstrate the reactiveness, robustness
            and generalizability of CherryBot to varying object shapes
            and dynamics in zero-shot settings (e.g., external disturbances
            like wind and human perturbations). 
          </p>
        </div>
      </div>
      
    </div>
    <!--/ Abstract. -->

  </div>

    <!-- Paper video. -->
    <!--
    </br>
    </br>
    <div class="columns is-centered has-text-centered">
      <div class="column is-two-thirds">
        <h2 class="title is-3">Video</h2>
        <div class="publhttps://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.thekitchn.com%2Fnostress-solution-how-to-get-t-108285&psig=AOvVaw0y0Ig-QftM9qU6kjN_uCnS&ust=1668638482016000&source=images&cd=vfe&ved=0CAwQjRxqFwoTCMCrj_SgsfsCFQAAAAAdAAAAABAborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    -->
</section>

<section class="section">
  <div class="container is-max-desktop has-text-centered">
    <h2 class="title is-3">Our System</h2>
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <video controls poster="media/imgs/tycho_narrative_thumbnail.png">
          <source src="media/vids/tycho_narrative.mp4" type="video/mp4" />
          Video description of our system.
        </video>
      </div>
    </div>
    <div class="content">
      <p>
        Our system, CherryBot, can handle challenging
        dynamic fine manipulation tasks in the real world. CherryBot
        operates in three phases: (1) pretraining in simulation on the
        proxy task, (2) fine-tuning in the real world on the same proxy
        task, and (3) deploying in the real world on test tasks. We then
        evaluate the resulting learned policy in a variety of dynamic
        scenarios. The image on the right details a deeper look at our 
        hardware setup. Our robot is an assembled 6-DOF robotic arm 
        equipped with chopsticks to perform fine manipulation, paired with 
        either a motion capture cage or an RGB-D camera for perception.
      </p>

    </div>
    <div class="columns is-centered is-vcentered">
      <div class="column">
        <img src="media/imgs/tycho_system.svg" alt="System figure" />
      </div>
      <div class="column is-three-fifths">
        <img src="media/imgs/hardware.png" />
      </div>
    </div>
    <h2 class="title is-4">Finetuning Reproducibility</h2>
    <div class="content">
      <p>
        After pretraining in simulation, our system can efficiently finetune in the real world.
        Aside from time taken up by resets, our system finetunes in as little as 30 minutes of interaction!
        This finetuning procedure is robust and reproducible, as illustrated below in a timelapse of finetuning over 3 different seeds.
      </p>
    </div>
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <video controls>
          <source src="media/vids/finetune.mp4" type="video/mp4" />
          Timelapse of the 3 seeds of the robot finetuning in the real world.
        </video>
      </div>
    </div>
      <div class="content">
      <p>
        Typically, the training procedure takes around 2.5 hours which contains 0.5 hours interaction and 2 hours reset. 
      </p>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop has-text-centered">
    <h2 class="title is-3">Results</h2>
    <h4 class="title is-4">Food Demonstrations</h4>
    <div class="columns is-centered is-multiline is-variable is-1">
      <div class="column is-half">
        <video controls muted autoplay loop>
          <source src="media/vids/food/vegetables.mp4" type="video/mp4" />
          Video of a robot picking up a cherry from a plate of vegetables.
        </video>
      </div>
      <div class="column is-half">
        <video controls muted autoplay loop>
          <source src="media/vids/food/vegetables_static.mp4" type="video/mp4" />
          Video of a robot picking up a cherry from a plate of vegetables.
        </video>
      </div>
      <div class="column is-half">
        <video controls muted autoplay loop>
          <source src="media/vids/food/chilis.mp4" type="video/mp4" />
          Video of the robot picking up chilis from a bowl.
        </video>
      </div>
      <div class="column is-half">
        <video controls muted autoplay loop>
          <source src="media/vids/food/chilis_static.mp4" type="video/mp4" />
          Video of the robot picking up chilis from a bowl.
        </video>
      </div>
      <div class="column is-half">
        <video controls muted autoplay loop>
          <source src="media/vids/food/kimchi.mp4" type="video/mp4" />
          Video of a robot picking up a piece of kimchi from a bowl of food.
        </video>
      </div>
      <div class="column is-half">
        <video controls muted autoplay loop>
          <source src="media/vids/food/kimchi_static.mp4" type="video/mp4" />
          Video of a robot picking up a piece of kimchi from a bowl of food.
        </video>
      </div>
      <div class="column is-half">
        <video controls muted autoplay loop>
          <source src="media/vids/food/tofu.mp4" type="video/mp4" />
          Video of a robot picking up a piece of tofu from a bowl of food.
        </video>
      </div>
      <div class="column is-half">
        <video controls muted autoplay loop>
          <source src="media/vids/food/tofu_static.mp4" type="video/mp4" />
          Video of a robot picking up a piece of tofu from a bowl of food.
        </video>
      </div>
      <div class="column is-half">
        <video controls muted autoplay loop>
          <source src="media/vids/food/granola.mp4" type="video/mp4" />
          Video of a robot picking up a cherry from a bowl of granola and milk.
        </video>
      </div>
      <div class="column is-half">
        <video controls muted autoplay loop>
          <source src="media/vids/food/granola_closeup.mp4" type="video/mp4" />
          Video of a robot picking up a cherry from a bowl of granola and milk.
        </video>
      </div>
      <div class="column is-half">
        <video controls muted autoplay loop>
          <source src="media/vids/food/granola_retry.mp4" type="video/mp4" />
          Video of a robot reactively retrying to a failure while picking up a cherry from a bowl of granola and milk.
        </video>
      </div>
      <div class="column is-half">
        <video controls muted autoplay loop>
          <source src="media/vids/food/granola_retry_closeup.mp4" type="video/mp4" />
          Video of a robot reactively retrying to a failure while picking up a cherry from a bowl of granola and milk.
        </video>
      </div>
    </div>
    <h4 class="title is-4">How Reactive is the Agent?</h4>
    <div class="is-centered">
      <div class="content">
        <p>
          Below are examples of a human, a handwritten 100Hz controller, and our RL agent
          attempting to grab a ball that is being bounced in the air by a motor.
          Use the dropdown to view different trials!
        </p>
      </div>
      <div style="flex-direction: row;display: flex; justify-content: flex-end; align-items: baseline; margin: 0 auto; max-width: 60%; min-width: 30ch">
        <label class="label" for="SideBySide_Select" style="margin-right: 5px">Currently viewing:</label>
        <select id="SideBySide_Select">
          <option value="8">Trial 1</option>
          <option value="2">Trial 2</option>
          <option value="3">Trial 3</option>
          <option value="4">Trial 4</option>
          <option value="5">Trial 5</option>
          <option value="6">Trial 6</option>
          <option value="7">Trial 7</option>
          <option value="1">Trial 8</option>
          <option value="9">Trial 9</option>
          <option value="10">Trial 10</option>
        </select>
      </div>
    </div>
    <div class="columns is-centered has-text-centered is-1 is-variable" id="SideBySide"></div>
    <h4 class="title is-4">How Generalizable is the Agent?</h4>
    <div class="content">
      <p>
        We chose evaluation tasks to effectively test our agent's ability to
        generalize from the proxy task to more practical settings.
        Particularly, these tasks feature real-world complications that
        are not present at training time, allowing us to test the agent's
        ability to compensate for them at test time.
      </p>
    </div>
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <video controls muted autoplay loop>
          <source src="media/vids/tycho_collage.mp4" type="video/mp4" />
          Collage of robot performing a variety of real-world tasks.
        </video>
      </div>
    </div>
    <h4 class="title is-4">How Robust is the Agent?</h4>
    <div class="content">
      <p>
        Through the use of a challenging proxy task, our agent can stay robust to unmodeled dynamics.
        The following video showcases the robot successfully grabbing a ball that is being shaken around by a human.
      </p>
    </div>
    <div class="columns is-centered has-text-centered">
      <div class="column is-half">
        <video controls muted preload="none" poster="media/imgs/human_disturb_thumbnail.jpg">
          <source src="media/vids/human_disturb.mp4" type="video/mp4" />
          Longer video of robot grabbing a ball being disturbed by a human.
        </video>
      </div>
    </div>
  </div>

    <!-- Paper video. -->
    <!--
    </br>
    </br>
    <div class="columns is-centered has-text-centered">
      <div class="column is-two-thirds">
        <h2 class="title is-3">Video</h2>
        <div class="publhttps://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.thekitchn.com%2Fnostress-solution-how-to-get-t-108285&psig=AOvVaw0y0Ig-QftM9qU6kjN_uCnS&ust=1668638482016000&source=images&cd=vfe&ved=0CAwQjRxqFwoTCMCrj_SgsfsCFQAAAAAdAAAAABAborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    -->
</section>
<section class="section">
  <div class="container is-max-desktop has-text-centered">
    <h2 class="title is-3">Design Ablations</h2>
    <h4 class="title is-4">Finetuning</h4>
    <div class="horizontal_list">
      <span class="list_image">
        <img src="media/svg/finetune.svg" alt="Plot of UTD ablation" style="max-width: 100%; max-height: 100%;" />
        <p class="image_caption">Asynchronous update, high Update-To-Data (UTD) ratio and LayerNorm
          regularization yields a moderate improvement in sample efficiency while pretraining in simulation, 
          but greatly improves the speed of training during the real-world
          finetuning stage.</p>
      </span>
      <span class="list_image">
        <img src="media/svg/iql.svg" alt="Plot of IQL vs SAC" style="max-width: 100%; max-height: 100%;" />
        <p class="image_caption">We found that standard online RL algorithms (such as soft
          actor critic (SAC)) are far more effective for fine-tuning
          than targeted offline RL methods.</p>
      </span>
    </div>
    <div class="content is-centered has-text-centered" style="margin-top: 20px;">
      <p style="background-color: peachpuff; max-width: 50%; border-radius: 5px; border: 2px solid gray; margin: 0 auto; padding: 5px">
        Insight: Pre-training using standard off-policy RL methods
        with imperfect prior data from simulation and heuristic
        controllers can significantly help with sample efficiency for
        real-world fine-tuning
      </p>
    </div>
    <h4 class="title is-4">Heirarchical Controller</h4>
    <div class="horizontal_list">
      <span class="list_image">
        <img src="media/svg/100hz.svg" alt="Plot of 20hz vs 100hz" style="max-width: 100%; max-height: 100%;" />
        <p class="image_caption">The choice of control frequency can critically affect
          the horizon of the task. A higher control frequency effectively
          increases the time steps required to conduct a task and
          negatively impacts sample efficiency.</p>
      </span>
      <span class="list_image">
        <img src="media/svg/latency.svg" class="interpolation-image" alt="Plot of latency ablation" />
        <p class="image_caption">Latency's impact becomes negligible when the control frequency
          is lower, which decreases the relative ratio of the length of the
          latency over the length of the control step.</p>
      </span>
    </div>
    <div class="content is-centered has-text-centered" style="margin-top: 20px;">
      <p style="background-color: peachpuff; max-width: 50%; border-radius: 5px; border: 2px solid gray; margin: 0 auto; padding: 5px">
        Insight: Learning medium-frequency hybrid controllers can
        effectively balance policy reactivity against the tractability
        of learning
      </p>
    </div>
</section>


<!-- <section class="section">
  <div class="container is-max-desktop has-text-centered">
    <h2 class="title is-3">Additional results for rebuttal </h2>
    <h4 class="title is-4">Layernorm</h4>
    <div class="horizontal_list">
      <span class="list_image">
        <img src="media/imgs/ln_new.png" alt="Plot of UTD ablation" style="max-width: 80%; max-height: 80%;" />

      </span>
      
    </div>
    
    <h4 class="title is-4">Using YOLO as detection module</h4>
    <div class="horizontal_list">
        
    </div>
    <h4 class="title is-4">Trying Segmente Anything Model as detection module</h4>
    <div class="horizontal_list">
        
    </div>
</section> -->

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column">
        <div class="content has-text-centered">
          <p>
            Website template borrowed from <a href="https://github.com/nerfies/nerfies.github.io">NeRFies</a> made by the amazing <a href="https://keunhong.com/">Keunhong Park</a>. 
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-YZLKKYGP2M"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-YZLKKYGP2M');
</script>
</body>

</html>

